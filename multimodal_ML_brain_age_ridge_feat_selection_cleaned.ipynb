{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b19002f8-2acd-4bdd-92a9-9d58e2719bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import seaborn as sb  \n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import scale, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, RepeatedKFold, cross_validate, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.utils import resample \n",
    "from imaging_features import hyperintensities_flair, dti, cbf, resting_state_activation, ventricular_volume, surface_area, cortical_thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d7a74-1146-4c73-bd39-4c91be966430",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "The following helper functions are used to: \n",
    "- `train_model`: select model and scaler type and train the model\n",
    "- `predict_ages`: apply the model to the test sample to obtain the predicted ages\n",
    "- `evaluate_feature_ablation`: ablate one out of seven sets of feautres iteratively, and obtain the results for test sample(s) for both patients and health controls (optionally)\n",
    "- `calculate_mae`: evaluate the performance of the model using mean absolute error (MAE)\n",
    "- `plot_scatter_with_regression`: plot the scatter plot of the predicted age vs the chronological age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497c3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, model_type='ridge', scaler_type='minmax'):\n",
    "    \"\"\"\n",
    "    Train a regression model (Ridge or SVM) with cross-validation to find optimal parameters.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training labels (ages)\n",
    "        model_type: Type of model ('ridge' or 'svm')\n",
    "        scaler_type: Type of scaler ('minmax' or 'standard')\n",
    "    \n",
    "    Returns:\n",
    "        tuple containing:\n",
    "        - trained_model: Optimized regression model\n",
    "        - scaler: Fitted scaler (MinMaxScaler or StandardScaler)\n",
    "    \"\"\"\n",
    "    # Choose scaler based on model type\n",
    "    scaler = MinMaxScaler() if scaler_type == 'minmax' else StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Setup cross-validation\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=1)\n",
    "    \n",
    "    if model_type == 'ridge':\n",
    "        # Ridge Regression with cross-validation\n",
    "        alphas = 10**np.linspace(10, -2, 100) * 0.5\n",
    "        ridgecv = RidgeCV(alphas=alphas, scoring='neg_mean_absolute_error', cv=cv)\n",
    "        ridgecv.fit(X_train_normalized, y_train)\n",
    "\n",
    "        # Train final Ridge model with best alpha\n",
    "        final_model = Ridge(alpha=ridgecv.alpha_)\n",
    "    \n",
    "    elif model_type == 'svm':\n",
    "        # Support Vector Regression (SVR) with hyperparameter tuning\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "            'epsilon': [0.01, 0.1, 1],  # Tolerance margin for predictions\n",
    "            'kernel': ['linear', 'rbf']  # Different kernels for flexibility\n",
    "        }\n",
    "        svr = SVR()\n",
    "        grid_search = GridSearchCV(svr, param_grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "        grid_search.fit(X_train_normalized, y_train)\n",
    "\n",
    "        # Train final SVR model with best parameters\n",
    "        final_model = SVR(**grid_search.best_params_)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "    # Train the chosen model\n",
    "    final_model.fit(X_train_normalized, y_train)\n",
    "    \n",
    "    return final_model, scaler\n",
    "\n",
    "\n",
    "def predict_ages(model, scaler, X):\n",
    "    \"\"\"\n",
    "    Make age predictions using trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Ridge regression model\n",
    "        scaler: Fitted MinMaxScaler\n",
    "        X: Features to predict on\n",
    "        \n",
    "    Returns:\n",
    "        numpy array of predicted ages, rounded to 3 decimals\n",
    "    \"\"\"\n",
    "    X_normalized = scaler.transform(X)\n",
    "    predictions = model.predict(X_normalized)\n",
    "    return np.round(predictions, 3)\n",
    "\n",
    "def evaluate_feature_ablation(df_train_control, df_test_disease,  model_type, scalar_type,  df_test_control=None):\n",
    "    \"\"\"\n",
    "      Train a regression model (Ridge or SVM) with cross-validation to find optimal parameters.\n",
    "\n",
    "    This function normalizes the training features using the specified scaler, \n",
    "    then trains the selected model type using cross-validation to determine the best hyperparameters. \n",
    "    The trained model and the scaler used for normalization are returned for future predictions.\n",
    "\n",
    "    Args:\n",
    "        X_train (array-like): Training features (input data).\n",
    "        y_train (array-like): Training labels (target values, e.g., ages).\n",
    "        model_type (str, optional): Type of model to train ('ridge' for Ridge Regression or 'svm' for Support Vector Regression). Default is 'ridge'.\n",
    "        scaler_type (str, optional): Type of scaler to use for normalization ('minmax' for MinMaxScaler or 'standard' for StandardScaler). Default is 'minmax'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - trained_model: The optimized regression model (Ridge or SVR).\n",
    "            - scaler: The fitted scaler (MinMaxScaler or StandardScaler) used for normalizing the input features.\n",
    "    \"\"\"\n",
    "    results_disease = []\n",
    "    results_control = []\n",
    "    \n",
    "    for feature in [hyperintensities_flair, dti, cbf, resting_state_activation, ventricular_volume, surface_area, cortical_thickness]:\n",
    "        X_train_control = df_train_control.drop(['Age at Visit', 'BD#', 'Dx'] + feature, axis=1).astype('float64')\n",
    "        X_test_disease = df_test_disease.drop(['Age at Visit', 'BD#', 'Dx'] + feature, axis=1).astype('float64')\n",
    "        y_train_control =  df_train_control['Age at Visit'] # Train model\n",
    "        \n",
    "        model, scaler = train_model(X_train_control, y_train_control, model_type=model_type, scaler_type=scalar_type)\n",
    "        y_pred_disease = predict_ages(model, scaler, X_test_disease)\n",
    "        results_disease.append(y_pred_disease)\n",
    "\n",
    "        if df_test_control is not None:\n",
    "            X_test_control = df_test_control.drop(['Age at Visit', 'BD#', 'Dx'] + feature, axis=1).astype('float64')\n",
    "            y_pred_control = predict_ages(model, scaler, X_test_control)\n",
    "            results_control.append(y_pred_control)\n",
    "\n",
    "    return results_disease, results_control\n",
    "\n",
    "\n",
    "def calculate_mae(predictions_list, y_test):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Absolute Error (MAE) for a list of prediction arrays.\n",
    "\n",
    "    Args:\n",
    "        predictions_list: List of numpy arrays containing predicted values.\n",
    "        y_test: Numpy array of ground truth values.\n",
    "\n",
    "    Returns:\n",
    "        List of MAE values for each prediction array.\n",
    "    \"\"\"\n",
    "    mae_results = []\n",
    "    for predictions in predictions_list:\n",
    "        mae = np.mean(np.abs(predictions - y_test))\n",
    "        mae_results.append(mae)\n",
    "    return mae_results\n",
    "\n",
    "\n",
    "def plot_scatter_with_regression(y_test, y_pred, title=\"\", save_path=None):\n",
    "    \"\"\"Create a scatter plot of actual vs predicted ages with a regression line.\n",
    "    \n",
    "    Args:\n",
    "        y_test (array-like): True age values.\n",
    "        y_pred (array-like): Predicted age values.\n",
    "        title (str, optional): Title of the plot.\n",
    "        save_path (str, optional): Path to save the figure. If None, the plot is displayed instead.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 6))  # Set figure size\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.scatter(y_test, y_pred, alpha=0.7, edgecolors='k', linewidth=1)  \n",
    "\n",
    "    # Regression line\n",
    "    coefficients = np.polyfit(y_test, y_pred, 1)\n",
    "    x_range = np.linspace(min(y_test), max(y_test), 100)\n",
    "    y_range = np.polyval(coefficients, x_range)\n",
    "    plt.plot(x_range, y_range, color='red', linewidth=2, label=f'Regression line: y={coefficients[0]:.2f}x + {coefficients[1]:.2f}')\n",
    "    \n",
    "    # Pearson correlation coefficient\n",
    "    r, p_value = stats.pearsonr(y_test, y_pred)\n",
    "    plt.text(0.05, 0.9, f'Pearson r: {r:.2f}', transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "    # Grid, labels, and title\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.xlabel('Chronological Age', fontsize=12)\n",
    "    plt.ylabel('Predicted Age', fontsize=12)\n",
    "    plt.title(title if title else 'Scatter Plot with Regression Line', fontsize=14)\n",
    "    plt.legend()\n",
    "\n",
    "    # Save or show plot\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)  # Ensure directory exists\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()  # Close the figure to free memory\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18415350",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [\n",
    "    \"hyperintensities_flair\",\n",
    "    \"dti\",\n",
    "    \"cbf\",\n",
    "    \"resting_state_activation\",\n",
    "    \"ventricular_volume\",\n",
    "    \"surface_area\",\n",
    "    \"cortical_thickness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1423ec",
   "metadata": {},
   "source": [
    "Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82f175a-eab4-4f60-854a-daf3ee3efc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control = pd.read_excel('data_original/reducedata_hc1011.xlsx', header=1)\n",
    "df_disease = pd.read_excel('data_original/reducedata_bd1011.xlsx', header=1)\n",
    "\n",
    "df_control = df_control.drop(df_control.columns[0:2], axis=1) # drop first two columns that show indices\n",
    "df_disease = df_disease.drop(df_disease.columns[0:2], axis=1) # drop first two columns that show indices\n",
    "\n",
    "complete_participants = pd.read_csv('data_original/subject_id_complete.csv')\n",
    "complete_participants = complete_participants.rename(columns={\"stdyptid\": \"BD#\"}) #73 HC, 44 BD\n",
    "df_control = df_control.merge(complete_participants, on=['BD#', 'Dx'], how='inner') # inner join drops the values that are not matched in the other df\n",
    "df_disease = df_disease.merge(complete_participants,on=['BD#', 'Dx'], how='inner') # inner join drops the values that are not matched in the other df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8177f29f",
   "metadata": {},
   "source": [
    "### Training on full dataset of controls (73), Testing on full dataset of patients (44)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d9e47",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef33399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ridge_disease , _ = evaluate_feature_ablation(df_control, df_disease, 'ridge', 'minmax') # Predictions on BD sample from training on all HC sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3764af4d",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a2decc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_svm_disease , _ = evaluate_feature_ablation(df_control, df_disease, 'svm', 'minmax') # Predictions on BD sample from training on all "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42385e3",
   "metadata": {},
   "source": [
    "##### Ridge Regression Results: MAE when tested on full dataset of patients (44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "358f48c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE when the following feature set is ablated/omitted:\n",
      "hyperintensities_flair: 10.579\n",
      "dti: 10.513\n",
      "cbf: 9.952\n",
      "resting_state_activation: 10.134\n",
      "ventricular_volume: 10.010\n",
      "surface_area: 10.206\n",
      "cortical_thickness: 9.743\n"
     ]
    }
   ],
   "source": [
    "y_test_disease =  df_disease['Age at Visit']\n",
    "y_train_control =  df_control['Age at Visit']\n",
    "\n",
    "# Example usage\n",
    "mae_results_ridge_diease = calculate_mae(results_ridge_disease, y_test_disease)\n",
    "print(\"MAE when the following feature set is ablated/omitted:\")\n",
    "for f, mae in zip(feature_sets,  mae_results_ridge_diease):\n",
    "    print(f\"{f}: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe45e2",
   "metadata": {},
   "source": [
    "##### SVM Results: MAE when tested on full dataset of patients (44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf525d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE when the following feature set is ablated/omitted:\n",
      "hyperintensities_flair: 10.656\n",
      "dti: 11.241\n",
      "cbf: 10.350\n",
      "resting_state_activation: 10.269\n",
      "ventricular_volume: 10.349\n",
      "surface_area: 10.661\n",
      "cortical_thickness: 9.656\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "mae_results_svm_diease = calculate_mae(results_svm_disease, y_test_disease)\n",
    "print(\"MAE when the following feature set is ablated/omitted:\")\n",
    "for f, mae in zip(feature_sets,  mae_results_svm_diease):\n",
    "    print(f\"{f}: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15dfcb-1c63-421b-903f-81970e519ea0",
   "metadata": {},
   "source": [
    "### Training on subset of age-matched controls (51), Test on full dataset of patients (44) and subset of controls (22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1642fef7-ea18-4077-9772-f30ab9ce38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_control_train = pd.read_csv('data_processed/hc_train_age_proportion_match_bd.csv')\n",
    "subset_control_test = pd.read_csv('data_processed/hc_test_age_proportion_match_bd.csv')\n",
    "subset_control_train = subset_control_train.drop(columns=['age_group'])\n",
    "subset_control_test = subset_control_test.drop(columns=['age_group'])\n",
    "y_train_control =  subset_control_train['Age at Visit']\n",
    "y_test_control =  subset_control_test['Age at Visit']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bcc28d",
   "metadata": {},
   "source": [
    "##### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37b11778",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ridge_disease_trained_on_subset, results_ridge_control_trained_on_subset = evaluate_feature_ablation(subset_control_train, df_disease, model_type='ridge', scalar_type='minmax',df_test_control = subset_control_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b0cda",
   "metadata": {},
   "source": [
    "##### Ridge Regression Results: MAE when tested on full dataset of patients (44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2504f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for each omitted feature set:\n",
      "hyperintensities_flair: 10.949\n",
      "dti: 10.960\n",
      "cbf: 10.410\n",
      "resting_state_activation: 10.579\n",
      "ventricular_volume: 10.346\n",
      "surface_area: 10.587\n",
      "cortical_thickness: 9.932\n"
     ]
    }
   ],
   "source": [
    "mae = calculate_mae(results_ridge_disease_trained_on_subset, y_test_disease)\n",
    "print(\"MAE for each omitted feature set:\")\n",
    "for f, mae in zip(feature_sets, mae):\n",
    "    print(f\"{f}: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6609f8b",
   "metadata": {},
   "source": [
    "##### Ridge Regression Results: MAE when tested on subset of controls (22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8026fdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for each omitted feature set:\n",
      "hyperintensities_flair: 11.194\n",
      "dti: 11.301\n",
      "cbf: 11.154\n",
      "resting_state_activation: 10.519\n",
      "ventricular_volume: 11.838\n",
      "surface_area: 10.853\n",
      "cortical_thickness: 11.920\n"
     ]
    }
   ],
   "source": [
    "mae_ridge_control_trained_on_subset= calculate_mae(results_ridge_control_trained_on_subset, y_test_control)\n",
    "print(\"MAE for each omitted feature set:\")\n",
    "for f, mae in zip(feature_sets, mae_ridge_control_trained_on_subset):\n",
    "    print(f\"{f}: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983a5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_svm_disease_trained_on_subset, results_svm_control_trained_on_subset = evaluate_feature_ablation(subset_control_train, df_disease, model_type='svm', scalar_type='minmax',df_test_control = subset_control_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08808b",
   "metadata": {},
   "source": [
    "##### SVM Results: MAE when tested on full dataset of patients (44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1949b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for each omitted feature set:\n",
      "Omit hyperintensities_flair: 11.654\n",
      "Omit dti: 11.889\n",
      "Omit cbf: 11.401\n",
      "Omit resting_state_activation: 11.326\n",
      "Omit ventricular_volume: 10.929\n",
      "Omit surface_area: 11.402\n",
      "Omit cortical_thickness: 10.428\n"
     ]
    }
   ],
   "source": [
    "mae = calculate_mae(results_svm_disease_trained_on_subset, y_test_disease)\n",
    "print(\"MAE for each omitted feature set:\")\n",
    "for f, mae in zip(feature_sets, mae):\n",
    "    print(f\"Omit {f}: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a709ff1",
   "metadata": {},
   "source": [
    "##### SVM Results: MAE when tested on subset of controls (22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "238e7961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for each omitted feature set:\n",
      "Omit hyperintensities_flair: 11.989\n",
      "Omit dti: 11.719\n",
      "Omit cbf: 11.211\n",
      "Omit resting_state_activation: 11.190\n",
      "Omit ventricular_volume: 12.255\n",
      "Omit surface_area: 11.352\n",
      "Omit cortical_thickness: 12.605\n"
     ]
    }
   ],
   "source": [
    "mae = calculate_mae(results_svm_control_trained_on_subset, y_test_control)\n",
    "print(\"MAE for each omitted feature set:\")\n",
    "for f, mae in zip(feature_sets, mae):\n",
    "    print(f\"Omit {f}: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eaf0f3",
   "metadata": {},
   "source": [
    "### Plot scatter plots of chronological age vs predicted age for each feature set\n",
    "- Plots below uses the results from Ridge Regression trained on subset of controls (51) and tested on subset of controls (22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca7e92ec-2e4e-4a0a-8cc2-ad3d578387ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"figures/multimodal_model\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "for f, x in zip(feature_sets, results_ridge_control_trained_on_subset):\n",
    "    title = f'Feature ablated: {f}'\n",
    "    save_path = os.path.join(save_folder, f\"results_ridge_control_trained_on_subset_{f}.png\")\n",
    "    plot_scatter_with_regression(y_test_control, x, title=title, save_path=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95f6764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, x in zip(feature_sets, results_ridge_disease_trained_on_subset):\n",
    "    title = f'Feature ablated: {f}'\n",
    "    save_path = os.path.join(save_folder, f\"results_ridge_disease_trained_on_subset_{f}.png\")\n",
    "    plot_scatter_with_regression(y_test_disease, x, title=title, save_path=save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RidgeModel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
